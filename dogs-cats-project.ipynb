{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Based Species Recognition","metadata":{}},{"cell_type":"markdown","source":"## Importing The Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:50.983110Z","iopub.execute_input":"2023-05-05T11:06:50.983543Z","iopub.status.idle":"2023-05-05T11:06:50.989379Z","shell.execute_reply.started":"2023-05-05T11:06:50.983501Z","shell.execute_reply":"2023-05-05T11:06:50.988442Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Preprocessing the Training set","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory('/kaggle/input/cat-and-dog/training_set/training_set/',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:50.990495Z","iopub.execute_input":"2023-05-05T11:06:50.990862Z","iopub.status.idle":"2023-05-05T11:06:51.164377Z","shell.execute_reply.started":"2023-05-05T11:06:50.990831Z","shell.execute_reply":"2023-05-05T11:06:51.163298Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Found 8005 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preprocessing the Test set","metadata":{}},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./255)\ntest_set = test_datagen.flow_from_directory('/kaggle/input/cat-and-dog/test_set/test_set/',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.167080Z","iopub.execute_input":"2023-05-05T11:06:51.167593Z","iopub.status.idle":"2023-05-05T11:06:51.213796Z","shell.execute_reply.started":"2023-05-05T11:06:51.167553Z","shell.execute_reply":"2023-05-05T11:06:51.212818Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Found 2023 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building the CNN","metadata":{}},{"cell_type":"markdown","source":"### Initialising the CNN","metadata":{}},{"cell_type":"code","source":"cnn = tf.keras.models.Sequential()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.217276Z","iopub.execute_input":"2023-05-05T11:06:51.217612Z","iopub.status.idle":"2023-05-05T11:06:51.226450Z","shell.execute_reply.started":"2023-05-05T11:06:51.217587Z","shell.execute_reply":"2023-05-05T11:06:51.225488Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Step 1 - Convolution","metadata":{}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.228204Z","iopub.execute_input":"2023-05-05T11:06:51.228625Z","iopub.status.idle":"2023-05-05T11:06:51.249850Z","shell.execute_reply.started":"2023-05-05T11:06:51.228593Z","shell.execute_reply":"2023-05-05T11:06:51.248905Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### Step 2 - Pooling","metadata":{}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.253136Z","iopub.execute_input":"2023-05-05T11:06:51.253441Z","iopub.status.idle":"2023-05-05T11:06:51.263167Z","shell.execute_reply.started":"2023-05-05T11:06:51.253416Z","shell.execute_reply":"2023-05-05T11:06:51.262117Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"### Adding a second convolutional layer","metadata":{}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.265147Z","iopub.execute_input":"2023-05-05T11:06:51.265592Z","iopub.status.idle":"2023-05-05T11:06:51.289049Z","shell.execute_reply.started":"2023-05-05T11:06:51.265562Z","shell.execute_reply":"2023-05-05T11:06:51.288037Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"### Step 3 - Flattening","metadata":{}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Flatten())","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.290508Z","iopub.execute_input":"2023-05-05T11:06:51.290942Z","iopub.status.idle":"2023-05-05T11:06:51.302278Z","shell.execute_reply.started":"2023-05-05T11:06:51.290909Z","shell.execute_reply":"2023-05-05T11:06:51.301281Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"### Step 4 - Full Connection","metadata":{}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.306078Z","iopub.execute_input":"2023-05-05T11:06:51.306396Z","iopub.status.idle":"2023-05-05T11:06:51.324058Z","shell.execute_reply.started":"2023-05-05T11:06:51.306372Z","shell.execute_reply":"2023-05-05T11:06:51.323099Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### Step 5 - Output Layer","metadata":{}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.325698Z","iopub.execute_input":"2023-05-05T11:06:51.326080Z","iopub.status.idle":"2023-05-05T11:06:51.344467Z","shell.execute_reply.started":"2023-05-05T11:06:51.326048Z","shell.execute_reply":"2023-05-05T11:06:51.343508Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"## Training the CNN","metadata":{}},{"cell_type":"markdown","source":"### Compiling the CNN","metadata":{}},{"cell_type":"code","source":"cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.346281Z","iopub.execute_input":"2023-05-05T11:06:51.346668Z","iopub.status.idle":"2023-05-05T11:06:51.359091Z","shell.execute_reply.started":"2023-05-05T11:06:51.346633Z","shell.execute_reply":"2023-05-05T11:06:51.358031Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"### Training the CNN on the Training set and evaluating it on the Test set","metadata":{}},{"cell_type":"code","source":"cnn.fit(x = training_set, validation_data = test_set, epochs = 25)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:06:51.362475Z","iopub.execute_input":"2023-05-05T11:06:51.362859Z","iopub.status.idle":"2023-05-05T11:19:19.076653Z","shell.execute_reply.started":"2023-05-05T11:06:51.362820Z","shell.execute_reply":"2023-05-05T11:19:19.075528Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1/25\n251/251 [==============================] - 31s 118ms/step - loss: 0.6586 - accuracy: 0.6071 - val_loss: 0.5943 - val_accuracy: 0.7088\nEpoch 2/25\n251/251 [==============================] - 29s 115ms/step - loss: 0.5861 - accuracy: 0.6934 - val_loss: 0.5524 - val_accuracy: 0.7177\nEpoch 3/25\n251/251 [==============================] - 29s 115ms/step - loss: 0.5476 - accuracy: 0.7235 - val_loss: 0.5604 - val_accuracy: 0.7133\nEpoch 4/25\n251/251 [==============================] - 29s 115ms/step - loss: 0.5206 - accuracy: 0.7388 - val_loss: 0.5595 - val_accuracy: 0.7197\nEpoch 5/25\n251/251 [==============================] - 29s 115ms/step - loss: 0.5006 - accuracy: 0.7535 - val_loss: 0.5055 - val_accuracy: 0.7603\nEpoch 6/25\n251/251 [==============================] - 29s 115ms/step - loss: 0.4746 - accuracy: 0.7694 - val_loss: 0.5056 - val_accuracy: 0.7563\nEpoch 7/25\n251/251 [==============================] - 29s 117ms/step - loss: 0.4559 - accuracy: 0.7814 - val_loss: 0.4686 - val_accuracy: 0.7751\nEpoch 8/25\n251/251 [==============================] - 30s 118ms/step - loss: 0.4426 - accuracy: 0.7894 - val_loss: 0.4755 - val_accuracy: 0.7761\nEpoch 9/25\n251/251 [==============================] - 30s 121ms/step - loss: 0.4242 - accuracy: 0.7976 - val_loss: 0.5204 - val_accuracy: 0.7435\nEpoch 10/25\n251/251 [==============================] - 30s 119ms/step - loss: 0.4198 - accuracy: 0.8089 - val_loss: 0.4675 - val_accuracy: 0.7855\nEpoch 11/25\n251/251 [==============================] - 30s 119ms/step - loss: 0.4033 - accuracy: 0.8155 - val_loss: 0.5350 - val_accuracy: 0.7677\nEpoch 12/25\n251/251 [==============================] - 29s 117ms/step - loss: 0.3861 - accuracy: 0.8219 - val_loss: 0.5222 - val_accuracy: 0.7538\nEpoch 13/25\n251/251 [==============================] - 29s 117ms/step - loss: 0.3703 - accuracy: 0.8342 - val_loss: 0.4474 - val_accuracy: 0.8047\nEpoch 14/25\n251/251 [==============================] - 29s 116ms/step - loss: 0.3546 - accuracy: 0.8450 - val_loss: 0.4793 - val_accuracy: 0.7899\nEpoch 15/25\n251/251 [==============================] - 29s 117ms/step - loss: 0.3451 - accuracy: 0.8478 - val_loss: 0.4791 - val_accuracy: 0.7988\nEpoch 16/25\n251/251 [==============================] - 29s 116ms/step - loss: 0.3273 - accuracy: 0.8566 - val_loss: 0.5115 - val_accuracy: 0.7939\nEpoch 17/25\n251/251 [==============================] - 30s 118ms/step - loss: 0.3151 - accuracy: 0.8643 - val_loss: 0.4584 - val_accuracy: 0.8176\nEpoch 18/25\n251/251 [==============================] - 30s 118ms/step - loss: 0.3013 - accuracy: 0.8717 - val_loss: 0.4866 - val_accuracy: 0.8008\nEpoch 19/25\n251/251 [==============================] - 30s 119ms/step - loss: 0.2970 - accuracy: 0.8702 - val_loss: 0.4537 - val_accuracy: 0.8028\nEpoch 20/25\n251/251 [==============================] - 29s 116ms/step - loss: 0.2784 - accuracy: 0.8844 - val_loss: 0.4926 - val_accuracy: 0.8043\nEpoch 21/25\n251/251 [==============================] - 30s 119ms/step - loss: 0.2682 - accuracy: 0.8907 - val_loss: 0.4933 - val_accuracy: 0.8028\nEpoch 22/25\n251/251 [==============================] - 29s 118ms/step - loss: 0.2501 - accuracy: 0.8981 - val_loss: 0.5175 - val_accuracy: 0.7929\nEpoch 23/25\n251/251 [==============================] - 29s 117ms/step - loss: 0.2360 - accuracy: 0.9067 - val_loss: 0.5130 - val_accuracy: 0.7993\nEpoch 24/25\n251/251 [==============================] - 29s 114ms/step - loss: 0.2310 - accuracy: 0.9033 - val_loss: 0.5185 - val_accuracy: 0.8052\nEpoch 25/25\n251/251 [==============================] - 29s 116ms/step - loss: 0.2177 - accuracy: 0.9092 - val_loss: 0.6200 - val_accuracy: 0.7899\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x76376e4a78b0>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Making a single prediction","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\ntest_image = load_img('/kaggle/input/single-prediction-dogcat/cat_dog10.jpg', target_size = (64, 64))\ntest_image = img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n  prediction = 'dog'\nelse:\n  prediction = 'cat'","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:22:53.378718Z","iopub.execute_input":"2023-05-05T11:22:53.379286Z","iopub.status.idle":"2023-05-05T11:22:53.616318Z","shell.execute_reply.started":"2023-05-05T11:22:53.379255Z","shell.execute_reply":"2023-05-05T11:22:53.615295Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 132ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"print(prediction)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T11:23:20.041579Z","iopub.execute_input":"2023-05-05T11:23:20.041949Z","iopub.status.idle":"2023-05-05T11:23:20.048661Z","shell.execute_reply.started":"2023-05-05T11:23:20.041920Z","shell.execute_reply":"2023-05-05T11:23:20.047485Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"dog\n","output_type":"stream"}]}]}